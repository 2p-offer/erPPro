# redis 的持久化策略：



## RDB

>  rdb 是一种快照持久化方式，redis会在触发某种条件的情况下， 为当前的内存数据，dump出一个快照文件。

- RDB完成后会自动生成一个文件，保存在`dir`配置的指定目录下，文件名是`dbfileName`指定。
- Redis默认会采用LZF算法对生成的RDB文件做压缩处理，压缩后的文件远远小于内存大小，默认开启



什么情况下会dump呢？

1. 手动触发[少用]：
   - save
   - bgsave
2. 自动触发：
   - 根据redis.conf 配置的save second times ，来决定自动触发dump
   - 如果从节点执行全量复制操作，主节点自动执行bgSave,并发送给从节点
   - 执行 debug reload 命令 重新加载redis。会触发save
   - 当调用shutdown 时，如果没有开启AOF,则会调用bgSav

执行流程：



![RDB执行流程](https://gitee.com/chenjiabing666/Blog-file/raw/master/Redis%E6%8C%81%E4%B9%85%E5%8C%96/RDB%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B.png)



> 优点 ： RDB 生成的快照文件，是压缩后的二进制文件，非常适合备份以及数据同步，恢复。并且加载数据的时候，RDB方式效率高于AOF



> 缺点：数据的持久化没有办法做到实时，或者秒级。



## AOF



> AOF （append only file） 以独立日志的方式，追加每次的写操作命令。重启时，重新执行aof文件内的命令达到数据恢复目的。主要解决了数据持久化的实时性



- 如何开启AOF?

  开启AOF功能需要设置redis.conf配置：`appendonly yes`， 默认不开启。 AOF文件名通过`appendfilename`配置设置， 默认文件名是`appendonly.aof`。 保存路径同RDB持久化方式一致，通过`dir`配置指定。



- AOF 如何进行持久化？

  AOF命令写入的内容直接是文本协议格式。 例如`set key1 value1这条命
  令， 在AOF缓冲区会追加如下文本：

```bash
$1
0
*3
$3
set
$4
key1
$6
value1
```



​	命令写入是直接写入到AOF的缓冲区中，至于为什么？原因很简单，Redis使用单线程响应命令，如果每次写AOF文件命令都直接追加到硬盘， 那么性能完全取决于当前硬盘负载。先写入缓冲区`aof_buf`中， 还有另一个好处， Redis可以提供多种缓冲区
同步硬盘的策略，在性能和安全性方面做出平衡



- AOF 持久化策略：

  ```bash
  # appendfsync always
  appendfsync everysec
  # appendfsync no
  ```

  

  由cof配置下的appendfsync 参数配置。支持三种：

  - always  每次写入都要同步aof文件
  - no 不持久化
  - everysec 每秒同步一次aof文件

- AOF 重写机制

随着写入命令的追加，日志文件越来越大，导致redis重新加载数据时，执行时间很长。所以引入了日志文件重写机制，用于缩减日志文件体积。从而使得更快的被redis加载

重写分为两种： 

1. 手动触发：

   直接使用`bgrewriteaof`命令手动触发重写

2. 自动触发：

   根据`auto-aof-rewrite-min-size`和`auto-aof-rewrite-percentage`参数确定自动触发时机。

   - `auto-aof-rewrite-min-size`：表示运行AOF重写时文件最小体积， 默认为64MB。
   - `auto-aof-rewrite-percentage`：代表当前AOF文件空间（`aof_current_size`） 和上一次重写后AOF文件空间（`aof_base_size`） 的比值。

重写后，怎么会变小呢？

1. 进程内已经超时的数据将不会再次写入AOF文件中。
2. 旧的AOF文件含有无效命令，如`del key1`、 `hdel key2`等。重写使用进程内数据直接生成，这样新的AOF文件只保留最终数据的写入命令。
3. 多条写命令可以合并为一个， 如：`lpush list a`、 `lpush list b`、`lpush listc`可以转化为：`lpush list a b c`。为了防止单条命令过大造成客户端缓冲区溢出，对于`list`、 `set`、 `hash`、 `zset`等类型操作，以64个元素为界拆分为多条。

重写流程：

​	![文件重写](https://gitee.com/chenjiabing666/Blog-file/raw/master/Redis%E6%8C%81%E4%B9%85%E5%8C%96/%E6%96%87%E4%BB%B6%E9%87%8D%E5%86%99%E6%B5%81%E7%A8%8B.png)